# Replicable News Aggregator Project Guide

## 1. Introduction

This guide details the architecture and development process of an automated news aggregation website. It is designed to be used by developers or an AI assistant to replicate this project for any chosen niche. The goal is to create a static HTML website that automatically fetches, categorizes, and displays news from various sources daily.

**Core Functionality:**
*   Fetches news from RSS feeds, NewsAPIs, and Reddit.
*   Filters and categorizes content based on keywords.
*   Generates static HTML pages (main index, daily archives, **keyword-specific topic pages**).
*   Automates daily updates via GitHub Actions.
*   Includes SEO best practices (sitemap, meta tags).
*   **NEW: Keyword-filtered topic pages for enhanced content discovery and SEO**

## 2. Project Architecture Overview

The project is built with Python and leverages several key libraries and tools:

*   **Backend Logic (`aggregator.py`):**
    *   **Python:** Core programming language.
    *   **`requests`:** For making HTTP requests to APIs and RSS feeds.
    *   **`feedparser`:** For parsing RSS/Atom feeds.
    *   **`praw`:** For interacting with the Reddit API.
    *   **`jinja2`:** For templating HTML pages.
    *   **`langdetect`:** For filtering non-English content.
    *   Standard libraries: `os`, `datetime`, `json`, `re`.
*   **Configuration (`config.json`):**
    *   Manages excluded sites, low-quality URL patterns, and negative keywords.
*   **Frontend (`template.html`, `archive_index_template.html`, CSS):**
    *   Static HTML pages generated by the backend.
    *   Styling is done via CSS (can be embedded or separate).
*   **Automation (`.github/workflows/daily-update.yml`):**
    *   GitHub Actions workflow for daily execution of the aggregation script.
*   **SEO (`generate_sitemap.py`, `sitemap_template.xml`, `robots.txt`):**
    *   Scripts and templates for generating sitemaps and guiding search engine crawlers.
*   **Dependencies (`requirements.txt`):**
    *   Lists all necessary Python packages.

## 3. Replication Process: Building for a New Niche

To adapt this project for a new niche, an AI or developer will need to gather specific information about the target niche and then configure the project components accordingly.

### Phase 1: Niche Definition & Initial Configuration

This is the most critical phase. The AI/developer needs to define the scope of the new site.

**Questions to Ask the User (or for the AI to determine):**

1.  **Primary Niche/Topic:** What is the central theme of the news site (e.g., "Triathlon & Endurance Sports", "Sustainable Technology", "Indie Game Development")?
2.  **Site Name/Brand:** What will the website be called?
3.  **Key Categories:** What are the main sub-topics or categories within this niche (e.g., for Triathlon: "Race Results", "Training Tips", "Gear Reviews", "Nutrition")?
4.  **Target Keywords:**
    *   What are 3-5 primary keywords for this niche?
    *   What are 5-10 secondary keywords?
    *   What are some relevant long-tail keywords?
5.  **Specific RSS Feeds:** Can you list at least 5-10 trusted RSS feeds for this niche (blogs, official organizations, news sites)?
6.  **Relevant Reddit Subreddits:** Can you list 3-5 relevant Reddit subreddits?
7.  **General News Query (for NewsAPI):** Formulate a broad query string for NewsAPI to capture general news related to the niche (e.g., `'(triathlon OR ironman) AND (news OR race OR training)'`).
8.  **Negative Keywords:** Are there any specific keywords that should *exclude* an article (e.g., for a "Sustainable Technology" site, perhaps "cryptocurrency mining" if not desired)?
9.  **Excluded Sites/Domains:** Are there any specific websites that should be ignored?

**Configuration Steps:**

Once the above information is gathered:

1.  **Update `aggregator.py` Constants:**
    *   `NEWS_API_QUERY`: Set based on question #7.
    *   `SUBREDDITS`: Set based on question #6.
    *   `MAX_REDDIT_POSTS_PER_SUB`: Adjust as needed (default is low, can be increased).
    *   `RSS_FEEDS`: Populate the dictionary with niche-specific feeds from question #5.
        ```python
        RSS_FEEDS = {
            "Niche Source 1 Name": "URL_to_RSS_feed_1",
            "Niche Source 2 Name": "URL_to_RSS_feed_2",
            # ... add all feeds
        }
        ```
    *   `CATEGORIES`: Define a list of category names based on question #3.
        ```python
        CATEGORIES = [
            'Niche Category 1',
            'Niche Category 2',
            # ... add all categories
        ]
        ```
    *   `CATEGORY_KEYWORDS`: This is crucial. Create a dictionary where keys are the `CATEGORIES` defined above, and values are lists of keywords that assign an article to that category. This often requires iteration and refinement.
        ```python
        CATEGORY_KEYWORDS = {
            'Niche Category 1': ['keyword1', 'keyword2', 'phrase for category 1'],
            'Niche Category 2': ['keyword3', 'keyword4'],
            # ... for all categories
        }
        ```
    *   `TRENDING_KEYWORDS`: (Optional) Keywords that might push an article into a "Trending" category.
    *   `MAX_HEADLINE_WORDS`: Adjust if needed (default: 8).

2.  **Update `config.json`:**
    *   `excluded_sites`: Add any domains to ignore based on question #9.
    *   `negative_keywords`: Add keywords that should filter out articles, based on question #8.
    *   `low_quality_url_patterns`: Keep the defaults unless specific patterns for the niche are known.

3.  **Update `template.html` (and `archive_index_template.html`):**
    *   **Site Title:** Change `<title>AI Flash Report - Daily AI News</title>` to reflect the new niche and site name.
    *   **Meta Description & Keywords:**
        *   `<meta name="description" content="...">`: Update with a compelling description using primary and secondary keywords for the new niche.
        *   `<meta name="keywords" content="...">`: Update with the target keywords from question #4.
    *   **Open Graph & Twitter Card Tags:**
        *   Update `og:title`, `og:description`, `og:image`, `og:url`, `og:site_name`.
        *   Update `twitter:title`, `twitter:description`, `twitter:image`.
        *   *Ensure placeholder image paths (`/images/og-image.png`, etc.) are noted so the user knows to create these images.*
    *   **Schema.org Structured Data:**
        *   Update `headline`, `publisher.name`, `publisher.logo.url`, and `description` to match the new niche.
        *   *Note the need for a `logo.png` in `/images/`.*
    *   **Site Header/Logo:** Update `<h1>` and any logo elements.
    *   **Footer:** Update copyright and any links.
    *   **Category Descriptions (if used in template):** If the template includes static text per category, ensure this is updated or made dynamic.

4.  **Update `README.md`:**
    *   Reflect the new project's name, niche, and purpose.
    *   Update setup instructions if any specific changes were made.

5.  **Update `generate_sitemap.py` & `sitemap_template.xml`:**
    *   Ensure the base URL in `sitemap_template.xml` (`<loc>https://aiflashreport.com...</loc>`) is changed to the new site's domain. The `generate_sitemap.py` script will use this template.

6.  **Update `robots.txt`:**
    *   Ensure `Sitemap:` directive points to the correct `sitemap.xml` URL for the new domain.

### Phase 2: Technical Setup

1.  **Clone/Copy Base Project:** Start with a copy of the original project files.
2.  **Python Virtual Environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```
3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    The `requirements.txt` should contain:
    ```
    requests
    feedparser
    praw
    Jinja2
    langdetect
    # Add other specific versions if necessary
    ```
4.  **API Keys & Environment Variables:**
    The script requires API keys for NewsAPI and Reddit. These must be set as environment variables.
    *   `NEWS_API_KEY`
    *   `REDDIT_CLIENT_ID`
    *   `REDDIT_CLIENT_SECRET`
    *   `REDDIT_USER_AGENT` (e.g., `"web:yournicheaggregator:v0.1 (by /u/yourusername)"`)
    *   `PERPLEXITY_API_KEY` (Optional, can be removed if not used for the new niche)

    These can be set in the shell or a `.env` file (ensure `.env` is in `.gitignore`).

### Phase 3: Customization & Branding

1.  **CSS Styling:** Modify the CSS in `template.html` (or a linked `style.css` file if separated) to match the desired look and feel for the new niche.
2.  **Images:** Create and place the necessary images:
    *   `/images/og-image.png` (1200x630px)
    *   `/images/twitter-card.png` (1200x600px)
    *   `/images/logo.png` (for Schema.org and site header)
    *   Favicon files (e.g., `favicon.ico`, `favicon-16x16.png`, etc.)
3.  **Content for Static Pages:**
    *   Update `about.html` with relevant information for the new site.
    *   Create any other static pages needed.

### Phase 3.5: Essential Forms & Boilerplate Pages

**Critical for Legal Compliance & User Engagement:**

1.  **Contact Form (`contact.html`):**
    *   **Purpose:** User feedback, content suggestions, partnership inquiries
    *   **Key Elements:**
        *   Contact form with fields: Name, Email, Subject (dropdown), Message
        *   Netlify form integration: `data-netlify="true"` and honeypot protection
        *   Form action pointing to success page: `action="/contact-success.html"`
        *   Professional styling matching site theme
        *   Header styling consistent with main template
    *   **Customization for New Niche:**
        *   Update subject dropdown options relevant to the niche
        *   Modify intro text and contact reasons
        *   Update social media links in contact info section
        *   Ensure footer navigation matches other pages

2.  **Privacy Policy (`privacy.html`):**
    *   **Purpose:** Legal compliance for data collection (GDPR/CCPA)
    *   **Required Sections:**
        *   Data collection practices (newsletter, contact form)
        *   Analytics usage (Plausible, ConvertBox)
        *   Cookie usage and management
        *   User rights and data retention
        *   Contact information for privacy requests
    *   **Customization for New Niche:**
        *   Update company/site name throughout
        *   Modify data collection descriptions based on actual forms used
        *   Adjust contact information and jurisdiction

3.  **Cookie Policy (`cookie-policy.html`):**
    *   **Purpose:** Transparency about cookie usage
    *   **Required Sections:**
        *   Essential cookies (site functionality)
        *   Analytics cookies (Plausible)
        *   Marketing cookies (ConvertBox)
        *   Instructions for disabling cookies
        *   Cookie consent management
    *   **Customization for New Niche:**
        *   Update site name and domain references
        *   Modify based on actual tracking tools used

4.  **Newsletter Signup Integration:**
    *   **Location:** Embedded in main template (`template.html`)
    *   **Key Features:**
        *   Email input with validation
        *   Netlify form processing
        *   Privacy policy link
        *   Spam protection (honeypot)
        *   Analytics tracking for conversions
    *   **Customization for New Niche:**
        *   Update value proposition text
        *   Modify subscriber count claims
        *   Adjust frequency options if needed

5.  **Footer Navigation Consistency:**
    *   **Required Links:** Home, Archive Index, About, Contact
    *   **Legal Links:** Privacy Policy, Cookie Policy (when created)
    *   **Implementation:** Must be consistent across all pages:
        *   `index.html` (main page)
        *   `about.html`
        *   `contact.html`
        *   `template.html` (for generated pages)
        *   Archive pages (via `archive_index_template.html`)

6.  **Success/Thank You Pages:**
    *   **Contact Success (`contact-success.html`):** Confirmation after form submission
    *   **Newsletter Thank You (`thank-you.html`):** Confirmation after newsletter signup
    *   **Customization:** Update messaging and next steps relevant to niche

**Implementation Checklist for New Niche:**
- [ ] Copy all form and policy page templates
- [ ] Update site name, domain, and contact information
- [ ] Customize form fields and options for niche relevance
- [ ] Ensure consistent header styling across all pages
- [ ] Update footer navigation on all pages
- [ ] Test form submissions and success page redirects
- [ ] Review legal compliance for target jurisdiction
- [ ] Link privacy policy from newsletter signup form

### Phase 4: Automation & Deployment

1.  **GitHub Repository:** Create a new GitHub repository for the project.
2.  **GitHub Actions Workflow (`.github/workflows/daily-update.yml`):**
    *   This file can largely be reused.
    *   **Crucial:** Set up GitHub Secrets in the new repository settings for all the API keys used in the `env` section of the workflow (`NEWS_API_KEY`, `REDDIT_CLIENT_ID`, etc.).
3.  **Hosting:**
    *   **Static Hosting Providers:** Netlify, GitHub Pages, Vercel, Cloudflare Pages are good options.
    *   Configure the chosen provider to build/deploy from the `main` branch of the GitHub repository. Usually, no complex build command is needed as HTML is committed directly.

### Phase 5: Testing, Maintenance & Iteration

1.  **Local Testing:** Run `python3 aggregator.py` locally to test data fetching, processing, and HTML generation. View `index.html` in a browser.
2.  **Deployment Testing:** Push changes to GitHub and monitor the GitHub Actions workflow. Check the live site after deployment.
3.  **Ongoing Maintenance:**
    *   Monitor for broken RSS feeds or API issues.
    *   Refine `CATEGORY_KEYWORDS` and `negative_keywords` based on the quality of aggregated content.
    *   Update dependencies and Python version as needed.
    *   Check Google Search Console for SEO issues and performance.

## 4. Developer & Project Rules (Best Practices)

These are inherited from the original project and are crucial for smooth development, especially with automated content generation.

*   **Git Workflow:**
    *   **Main Branch:** The `main` branch is the source of truth and what gets deployed.
    *   **Feature Branches:** Make changes on separate branches and merge via Pull Requests (optional for solo developers but good practice).
    *   **API Keys:** NEVER commit API keys or sensitive credentials. Use environment variables locally and GitHub Secrets for Actions.
    *   **Generated Files:**
        *   `index.html`, `archive/*.html`, `sitemap.xml` are auto-generated.
        *   **DO NOT MANUALLY EDIT THESE FILES.**
        *   Before committing changes to *code* (`aggregator.py`) or *templates* (`template.html`), if you've run the script locally, **you MUST restore/discard changes to these generated files**:
            ```bash
            git restore index.html archive/ sitemap.xml
            # or git checkout -- index.html archive/ sitemap.xml
            ```
        *   The GitHub Action is responsible for generating the final versions of these files.
    *   **Pull Before Push:** Always `git pull --rebase` (or `git pull`) before pushing changes to avoid conflicts, especially since the remote can be updated by the GitHub Action.
*   **Code Standards:**
    *   Keep `aggregator.py` well-commented, especially the data fetching and categorization logic.
    *   Ensure robust error handling (e.g., what happens if an RSS feed is down or an API key is invalid?). The script should ideally continue with other sources.
    *   Make configuration (keywords, sources) easy to update, primarily through `aggregator.py` constants and `config.json`.
*   **SEO Maintenance:**
    *   Regularly review meta descriptions and keywords in `template.html`.
    *   Submit `sitemap.xml` to Google Search Console.
    *   Monitor indexing status and crawl errors.

## 5. Example: Adapting for "Sustainable Technology News"

**AI/User Answers:**
1.  **Primary Niche:** Sustainable Technology
2.  **Site Name:** GreenTech Today
3.  **Key Categories:** Renewable Energy, Green Transportation, Sustainable Building, Circular Economy, Climate Tech
4.  **Keywords:**
    *   Primary: sustainable technology, green tech news, climate tech
    *   Secondary: renewable energy, electric vehicles, sustainable innovation
    *   Long-tail: latest advancements in solar power, circular economy business models
5.  **RSS Feeds:** `{"CleanTechnica": "...", "GreenBiz": "...", ...}`
6.  **Subreddits:** `["sustainability", "ClimateAction", "RenewableEnergy"]`
7.  **NewsAPI Query:** `'(sustainable OR sustainability OR "green tech" OR "climate tech" OR renewable) AND (technology OR innovation OR news OR breakthrough)'`
8.  **Negative Keywords:** `["politics", "fossil fuels investment"]`
9.  **Excluded Sites:** `["old-biased-site.com"]`

**AI/Developer Actions:**
*   Updates `RSS_FEEDS`, `CATEGORIES`, `CATEGORY_KEYWORDS`, `NEWS_API_QUERY` in `aggregator.py`.
*   Updates `negative_keywords`, `excluded_sites` in `config.json`.
*   Changes titles, meta tags, and branding in `template.html` to "GreenTech Today".
*   Creates `logo.png`, `og-image.png`, `twitter-card.png` with GreenTech Today branding.
*   Sets up new GitHub repo, secrets, and deploys via Netlify/GitHub Pages.

This guide provides a comprehensive framework. The key to success is careful configuration in Phase 1 and iterative refinement of keywords and sources based on the aggregated content quality.

## 6. Key Lessons Learned & Best Practices

This section documents critical insights from building and deploying automated news aggregation sites, providing guidance for future implementations across different niches.

### 6.1 Core Architecture Decisions

**Static Site Generation Approach:**
- **Advantage:** Static HTML files (`index.html`, daily archives `YYYY-MM-DD.html`, `archive.html`) provide excellent performance, SEO benefits, and simplified hosting
- **Tools:** Python + Jinja2 templating proved to be a lightweight yet powerful combination
- **Consideration:** Evaluate if static generation fits your niche requirements. For real-time updates or heavy user interaction, consider hybrid approaches

**Content Source Strategy:**
- **RSS Feeds:** Easier initial integration (no API keys), widely available, but quality varies
- **APIs (NewsAPI, Reddit):** More structured data and richer content, but require API key management, rate limits, and secure storage
- **Recommendation:** Start with RSS for simplicity, then add APIs as needed

**Content Quality Control:**
- **Essential Components:** Language filtering, duplicate detection (`processed_urls.json`), keyword-based categorization
- **Niche Adaptation:** Filtering and categorization logic must be tailored for each domain

### 6.2 Automation & Deployment

**GitHub Actions Best Practices:**
- **Workflow Benefits:** Excellent for daily content updates with automated checkout, Python setup, dependency installation, and file commits
- **Critical Pitfall:** Path handling in GitHub Action runners - commands execute from repository root
- **Required Permission:** Ensure `permissions: contents: write` for automated commits

**Static Content + SPA Integration:**
- **Key Directory:** Use `public/` directory in Vite projects - files are copied to build output root
- **Netlify Redirects:** Essential for SPA compatibility. Add specific redirect rules for static content paths before SPA catch-all rules:
  ```toml
  # Static content first
  /news/* /news/:splat 200
  /sitemap.xml /sitemap.xml 200
  # SPA catch-all last
  /* /index.html 200
  ```

**SEO Implementation:**
- **Sitemap Generation:** Separate Python script (`generate_sitemap.py`) for valid XML format
- **Common Error:** XML syntax strictness - avoid f-string backslash issues
- **Automation:** Integrate sitemap updates into GitHub Actions workflow

### 6.3 Development Workflow

**Git Management with Automation:**
- **Sync Issues:** GitHub Actions create commits that can desync local repositories
- **Best Practices:**
  - Always `git pull --rebase` before starting work and before pushing
  - Never manually edit auto-generated files (`index.html`, archives, `sitemap.xml`)
  - Use `git restore <generated_files>` before committing code changes
  - Maintain clear separation between "source code" and "generated artifacts"

**Configuration Management:**
- **Recommended Approach:** Use `config.json` for RSS feeds, keywords, and filters
- **Benefits:** Enables updates without code changes, easier niche adaptation

**Testing & Debugging:**
- **Local Preview:** Use `python -m http.server` from output directory
- **Path Awareness:** Local server paths may differ from live site structure
- **Essential Tools:** GitHub Action logs, Netlify deploy logs, browser developer tools

### 6.4 Common Issues & Solutions

**Frequent Challenges:**
- Jinja2 undefined variables
- Git merge conflicts from automated commits
- Path issues in scripts/workflows
- SPA routing conflicts with static content
- XML syntax errors in sitemap generation

**Critical Success Factors:**
1. **Early Planning:** Design Netlify redirects before SPA integration
2. **Strict Git Workflow:** Document and enforce separation of source vs. generated files
3. **Thorough Testing:** Validate all generation scripts before automation integration
4. **Configuration-Driven Design:** Maximize adaptability for new niches

### 6.5 Recommendations for New Niches

**Pre-Development Checklist:**
- [ ] Research available RSS feeds for quality and update frequency
- [ ] Plan API integration strategy and secret management
- [ ] Design keyword categorization system for the niche
- [ ] Establish Git workflow documentation
- [ ] Plan static content routing strategy

**Implementation Priority:**
1. Start with RSS feeds for rapid prototyping
2. Implement robust filtering and categorization
3. Set up automated deployment pipeline
4. Add API sources for enhanced content
5. Optimize SEO and performance

This framework has proven effective for creating scalable, maintainable news aggregation sites that can be efficiently adapted across different niches and domains.

## 7. Keyword Pages System

The keyword pages system extends the basic news aggregation functionality by creating topic-specific landing pages that filter content based on predefined keywords and criteria. This system significantly improves SEO, user experience, and content discoverability.

### 7.1 System Overview

**Purpose:**
- Create dedicated pages for specific topics (e.g., "OpenAI News", "Google AI News", "Machine Learning News")
- Improve SEO with topic-specific URLs and content
- Enhance user navigation and content discovery
- Support both automated filtering and manually curated content

**Key Components:**
1. **`keyword_config.json`** - Configuration file defining all keyword pages
2. **`keyword_template.html`** - Jinja2 template for keyword-specific pages
3. **Enhanced `aggregator.py`** - Core logic for filtering and generating keyword pages
4. **Navigation integration** - Dropdown menu system in main template
5. **Curated content support** - Manual content management for special pages

### 7.2 Configuration System (`keyword_config.json`)

The keyword configuration file defines all topic pages and their filtering criteria:

```json
{
  "openai-news": {
    "title": "OpenAI News",
    "filename": "openai-news.html",
    "description": "Latest news and updates from OpenAI, including ChatGPT, GPT models, and company announcements.",
    "page_type": "automated",
    "content_max_age_days": 7,
    "primary_keywords": ["openai", "chatgpt", "gpt-4", "gpt-3"],
    "secondary_keywords": ["sam altman", "dall-e", "whisper"],
    "required_keywords": ["openai"],
    "excluded_keywords": ["competitor", "criticism"],
    "minimum_score": 2.0,
    "max_articles": 50
  },
  "ai-news-today": {
    "title": "AI News Today",
    "filename": "ai-news-today.html", 
    "description": "Today's most important AI news, curated highlights and breaking developments.",
    "page_type": "curated",
    "curated_content_file": "curated_content/ai-news-today.json"
  }
}
```

**Configuration Fields:**
- **`title`**: Display name for the page
- **`filename`**: Output HTML filename
- **`description`**: Meta description for SEO
- **`page_type`**: Either "automated" (keyword filtering) or "curated" (manual content)
- **`content_max_age_days`**: How recent articles should be (optional, defaults to 30 days)
- **`primary_keywords`**: High-value keywords (score: 3 points each)
- **`secondary_keywords`**: Supporting keywords (score: 2 points each)
- **`required_keywords`**: At least one must be present
- **`excluded_keywords`**: Automatically filter out articles containing these
- **`minimum_score`**: Threshold for inclusion
- **`max_articles`**: Maximum articles per page
- **`curated_content_file`**: Path to manual content (for curated pages)

### 7.3 Template System (`keyword_template.html`)

The keyword template extends the main template with topic-specific functionality:

```html
{% extends "template.html" %}

{% block title %}{{ keyword_page_config.title }} - AI Flash Report{% endblock %}

{% block page_title %}{{ keyword_page_config.title }}{% endblock %}

{% block meta_tags %}
<meta name="description" content="{{ keyword_page_config.description }}">
<meta name="keywords" content="{{ keyword_page_config.primary_keywords | join(', ') }}, {{ keyword_page_config.secondary_keywords | join(', ') }}">
{% endblock %}
```

**Key Features:**
- Inherits all styling and functionality from main template
- Dynamic page titles and meta tags
- Automatic keyword-based SEO optimization
- Consistent navigation and branding

### 7.4 Core Implementation Functions

#### 7.4.1 Keyword Filtering Logic

```python
def matches_keywords(text, keywords, case_sensitive=False):
    """Check if text contains any of the specified keywords"""
    
def calculate_keyword_relevance_score(article, page_config):
    """Calculate relevance score based on keyword matches"""
    
def filter_articles_for_keyword_page(articles, page_config):
    """Filter and score articles for a specific keyword page"""
```

#### 7.4.2 Page Generation Functions

```python
def generate_keyword_pages_data(articles, keyword_config):
    """Process all keyword pages and return filtered data"""
    
def generate_keyword_page_files(keyword_pages_data, keyword_config, template_vars):
    """Generate HTML files for all keyword pages"""
```

### 7.5 Content Filtering Algorithm

The system uses a sophisticated scoring algorithm:

1. **Keyword Matching**: Search in title, description, and content
2. **Score Calculation**:
   - Primary keywords: +3 points each
   - Secondary keywords: +2 points each  
   - Required keywords: Must have at least one match
   - Excluded keywords: Immediate disqualification
3. **Age Filtering**: Only include articles within `content_max_age_days`
4. **Score Threshold**: Only articles above `minimum_score` are included
5. **Limit Enforcement**: Respect `max_articles` setting

### 7.6 Curated Content System

For manually managed pages, the system supports curated content files:

**Structure (`curated_content/ai-news-today.json`):**
```json
{
  "articles": [
    {
      "title": "Major AI Breakthrough Announced",
      "url": "https://example.com/article", 
      "source": "TechNews",
      "date": "2024-01-15",
      "description": "Description of the breakthrough..."
    }
  ],
  "last_updated": "2024-01-15T10:00:00Z"
}
```

### 7.7 Navigation Integration

The main template includes automatic navigation generation:

```html
<div class="dropdown">
  <button class="dropbtn">Topics</button>
  <div class="dropdown-content">
    {% if all_keyword_pages_config %}
      {% for page_key, page_info in all_keyword_pages_config.items() %}
        <a href="/{{ page_info.filename }}">{{ page_info.title }}</a>
      {% endfor %}
    {% endif %}
  </div>
</div>
```

### 7.8 SEO Enhancements

**Automatic SEO Features:**
- Topic-specific page titles and meta descriptions
- Keyword-optimized content
- Breadcrumb navigation for page hierarchy
- Automatic sitemap inclusion via `generate_sitemap.py`
- Schema.org structured data inheritance

**Implementation in `generate_sitemap.py`:**
```python
# Add keyword pages to sitemap
for page_key, page_config in keyword_config.items():
    keyword_pages.append({
        'filename': page_config['filename'],
        'title': page_config['title']
    })
```

### 7.9 Deployment and Maintenance

**GitHub Actions Integration:**
The keyword pages are automatically generated as part of the daily update workflow. No additional configuration needed - the system integrates seamlessly with existing automation.

**Maintenance Tasks:**
1. **Keyword Tuning**: Monitor page quality and adjust keyword lists
2. **Content Age Management**: Adjust `content_max_age_days` based on content velocity
3. **Score Threshold Optimization**: Fine-tune `minimum_score` for content quality
4. **Curated Content Updates**: Manually update curated content files as needed

### 7.10 Adapting for New Niches

**Step-by-Step Process:**

1. **Define Topic Pages**: Identify 5-10 key topic areas for your niche
2. **Research Keywords**: Compile primary and secondary keywords for each topic
3. **Create Configuration**: Build `keyword_config.json` with your topics
4. **Customize Template**: Update `keyword_template.html` branding if needed
5. **Test Locally**: Run aggregator and verify page generation
6. **Deploy**: Push to GitHub and verify automated updates

**Example for "Sustainable Technology" Niche:**
```json
{
  "solar-energy-news": {
    "title": "Solar Energy News",
    "filename": "solar-energy-news.html",
    "description": "Latest solar panel technology, installations, and renewable energy developments.",
    "page_type": "automated",
    "primary_keywords": ["solar energy", "solar panel", "photovoltaic"],
    "secondary_keywords": ["renewable energy", "clean energy", "sustainability"],
    "required_keywords": ["solar"],
    "minimum_score": 2.0,
    "max_articles": 40
  }
}
```

### 7.11 Performance Considerations

**Content Volume Management:**
- Use `max_articles` to prevent pages from becoming too large
- Implement `content_max_age_days` to keep content fresh
- Monitor page generation time in GitHub Actions logs

**SEO Optimization:**
- Each keyword page creates a unique URL for specific topics
- Improves long-tail keyword targeting
- Enables topic-specific social media sharing
- Supports more granular Google Search Console monitoring

### 7.12 Troubleshooting Common Issues

**No Articles on Keyword Pages:**
1. Check keyword matching logic - may be too restrictive
2. Verify `minimum_score` threshold isn't too high
3. Ensure `content_max_age_days` allows sufficient content
4. Review `excluded_keywords` for over-filtering

**Template Errors:**
1. Verify `keyword_template.html` exists in `templates/` directory
2. Check Jinja2 template syntax
3. Ensure `keyword_page_config` variable is properly passed

**Navigation Issues:**
1. Confirm `all_keyword_pages_config` is passed to all templates
2. Verify dropdown CSS is properly implemented
3. Check that generated URLs match actual file outputs

The keyword pages system represents a significant enhancement to the basic news aggregator, providing better user experience, improved SEO performance, and more sophisticated content organization. This system can be easily adapted to any niche by following the configuration and customization guidelines outlined above.

## 8. Future Enhancements and Advanced Features
